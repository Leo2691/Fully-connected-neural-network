{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d2d1443b14c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding mnist\n",
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test  = x_test.reshape(x_test.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape = (28*28,), init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(10,  init=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(784,), activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# model 1 with uniform initialization\n",
    "uniform_model = create_model(\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 2.3004 - accuracy: 0.1119 - val_loss: 2.2986 - val_accuracy: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 2.2966 - accuracy: 0.1124 - val_loss: 2.2931 - val_accuracy: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 2.2811 - accuracy: 0.1414 - val_loss: 2.2434 - val_accuracy: 0.2220\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.8975 - accuracy: 0.3163 - val_loss: 1.5406 - val_accuracy: 0.3889\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 1.2758 - accuracy: 0.5266 - val_loss: 1.0013 - val_accuracy: 0.6600\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.8353 - accuracy: 0.7288 - val_loss: 0.7096 - val_accuracy: 0.7942\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.6220 - accuracy: 0.8223 - val_loss: 0.5305 - val_accuracy: 0.8508\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.4986 - accuracy: 0.8613 - val_loss: 0.4536 - val_accuracy: 0.8747\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.4325 - accuracy: 0.8806 - val_loss: 0.4019 - val_accuracy: 0.8913\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3836 - accuracy: 0.8941 - val_loss: 0.3626 - val_accuracy: 0.9027\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.3423 - accuracy: 0.9062 - val_loss: 0.3272 - val_accuracy: 0.9127\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.3073 - accuracy: 0.9149 - val_loss: 0.2964 - val_accuracy: 0.9197\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2785 - accuracy: 0.9241 - val_loss: 0.2766 - val_accuracy: 0.9271\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2540 - accuracy: 0.9295 - val_loss: 0.2583 - val_accuracy: 0.9305\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.2330 - accuracy: 0.9359 - val_loss: 0.2279 - val_accuracy: 0.9398\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2156 - accuracy: 0.9399 - val_loss: 0.2149 - val_accuracy: 0.9430\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1994 - accuracy: 0.9448 - val_loss: 0.2148 - val_accuracy: 0.9419\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1853 - accuracy: 0.9481 - val_loss: 0.2012 - val_accuracy: 0.9444\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1740 - accuracy: 0.9511 - val_loss: 0.1955 - val_accuracy: 0.9472\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1627 - accuracy: 0.9540 - val_loss: 0.1904 - val_accuracy: 0.9476\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1543 - accuracy: 0.9564 - val_loss: 0.1758 - val_accuracy: 0.9512\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1449 - accuracy: 0.9590 - val_loss: 0.1697 - val_accuracy: 0.9536\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1366 - accuracy: 0.9604 - val_loss: 0.1675 - val_accuracy: 0.9537\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1296 - accuracy: 0.9627 - val_loss: 0.1506 - val_accuracy: 0.9572\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1225 - accuracy: 0.9644 - val_loss: 0.1494 - val_accuracy: 0.9579\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1168 - accuracy: 0.9664 - val_loss: 0.1471 - val_accuracy: 0.9587\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1105 - accuracy: 0.9681 - val_loss: 0.1429 - val_accuracy: 0.9602\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1056 - accuracy: 0.9702 - val_loss: 0.1419 - val_accuracy: 0.9598\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1006 - accuracy: 0.9710 - val_loss: 0.1417 - val_accuracy: 0.9613\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0957 - accuracy: 0.9724 - val_loss: 0.1747 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6b9cdf28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "uniform_model.fit(x_train, Y_train,\n",
    "                 batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(784,), activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \"\"\"\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# model 1 with uniform initialization\n",
    "glorot_model = create_model(\"glorot_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.7645 - accuracy: 0.8037 - val_loss: 0.3909 - val_accuracy: 0.8991\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3552 - accuracy: 0.9019 - val_loss: 0.3063 - val_accuracy: 0.9151\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2956 - accuracy: 0.9154 - val_loss: 0.2681 - val_accuracy: 0.9242\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2625 - accuracy: 0.9240 - val_loss: 0.2446 - val_accuracy: 0.9293\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2374 - accuracy: 0.9318 - val_loss: 0.2252 - val_accuracy: 0.9358\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2165 - accuracy: 0.9377 - val_loss: 0.2079 - val_accuracy: 0.9388\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1986 - accuracy: 0.9423 - val_loss: 0.1937 - val_accuracy: 0.9436\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1833 - accuracy: 0.9469 - val_loss: 0.1792 - val_accuracy: 0.9467\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1693 - accuracy: 0.9507 - val_loss: 0.1722 - val_accuracy: 0.9501\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1578 - accuracy: 0.9544 - val_loss: 0.1591 - val_accuracy: 0.9523\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1473 - accuracy: 0.9575 - val_loss: 0.1513 - val_accuracy: 0.9555\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1384 - accuracy: 0.9604 - val_loss: 0.1429 - val_accuracy: 0.9579\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1301 - accuracy: 0.9627 - val_loss: 0.1387 - val_accuracy: 0.9596\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1226 - accuracy: 0.9652 - val_loss: 0.1333 - val_accuracy: 0.9601\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.1161 - accuracy: 0.9672 - val_loss: 0.1289 - val_accuracy: 0.9616\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1101 - accuracy: 0.9686 - val_loss: 0.1217 - val_accuracy: 0.9634\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1045 - accuracy: 0.9704 - val_loss: 0.1171 - val_accuracy: 0.9633\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0994 - accuracy: 0.9714 - val_loss: 0.1151 - val_accuracy: 0.9648\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0948 - accuracy: 0.9725 - val_loss: 0.1178 - val_accuracy: 0.9658\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0906 - accuracy: 0.9736 - val_loss: 0.1055 - val_accuracy: 0.9672\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0865 - accuracy: 0.9750 - val_loss: 0.1021 - val_accuracy: 0.9686\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0824 - accuracy: 0.9761 - val_loss: 0.1037 - val_accuracy: 0.9686\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0788 - accuracy: 0.9767 - val_loss: 0.1009 - val_accuracy: 0.9685\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0756 - accuracy: 0.9778 - val_loss: 0.0980 - val_accuracy: 0.9704\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0722 - accuracy: 0.9790 - val_loss: 0.0938 - val_accuracy: 0.9707\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0692 - accuracy: 0.9797 - val_loss: 0.0934 - val_accuracy: 0.9704\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0664 - accuracy: 0.9804 - val_loss: 0.0915 - val_accuracy: 0.9709\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0635 - accuracy: 0.9817 - val_loss: 0.0877 - val_accuracy: 0.9709\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0610 - accuracy: 0.9821 - val_loss: 0.0891 - val_accuracy: 0.9720\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0583 - accuracy: 0.9830 - val_loss: 0.0872 - val_accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x69d16908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(x_train, Y_train,\n",
    "                 batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
